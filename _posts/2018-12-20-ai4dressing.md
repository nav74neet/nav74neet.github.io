---
layout: post
title:  "When AI learnt to dress!"
date:   2018-06-12
categories: [rl]
description: Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning.
tags: deep reinforcement learning, character animation, nueral networks,

---
<center>
            <div class="image-wrapper">
                <a class ="image-popup" href="https://nav74neet.github.io/media/blog/ai4dressing/ai4dressing.gif" title="ai4d">
                    <img src="https://nav74neet.github.io/media/blog/ai4dressing/ai4dressing.gif" alt="ai4d" align="middle">
                </a>
                <center>
                <p class="image-caption" style="font-size:10px; text-align:center;">
                    Courtesy: Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning [Alexander Clegg, et al., Siggraph 2018].
                </p>
                </center>
            </div>
</center>

## Intro  
<p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">Recently, one of the exciting works, to come out of Siggraph, 2018 is "<a href="https://www.cc.gatech.edu/~aclegg3/projects/learning-dress-synthesizing.pdf" class="md-link">Learning to Dress: Synthesizing Human Dressing Motion via Deep Reinforcement Learning</a>".</p>
<!-- <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">But the same cannot be said in the case of a walking robot. There are lots of physical constraints associated with the model and the environment the robot interacts with. This requires complex levels of control theory and accurate mathematical computations. But there's an alternative solution to the problem of bipedal walking robot - Reinforcement Learning.</p> -->