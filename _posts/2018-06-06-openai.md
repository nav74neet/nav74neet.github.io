---
layout: post
title:  "Solving OpenAI gym's environments using reinforcement and imitation learning techniques"
date:   2018-06-06
categories: [rl]
description: My solutions to tackle several OpenAI gym's environments using RL and imitation learning.
tags: reinforcement learning, dqn, policy gradient, gail, ppo, openai gym, cartpole, bipedwalker, gazebo, breakout, tensorflow, pytorch, 

---

## What's this post about?
<p style="text-align:justify">
This post mainly focuses on the implementation of RL and imitation learning techniques for classical OpenAI gym' environments like cartpole-v0, breakout, mountain car, bipedwalker-v2, etc. I have implemented several RL algorithms such as dqn, policy gradient, etc. as well as generative adversaral learning approach like GAIL for imitation learning.      
</p>

## Reinforcment learning Techniques.
<div class="row">
 <div class="col-md-8">
        <p style="text-align:justify">
          <b>[1] Deep Q-Networks for Breakout-v0</b>: Maximize the score in the Atari 2600 game Breakout. In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3) Each action is repeatedly performed for a duration of kkk frames, where kkk is uniformly sampled from {2,3,4}. 
          </p>
          <p>
          <a href="https://github.com/nav74neet/rl_gym/tree/master/breakout" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-5">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/breakout-v0.gif" title="DQN">
    <img src="https://nav74neet.github.io/media/blog/openaigym/breakout-v0.gif" alt="DQN" style="border:1px solid black;" align="middle">
    </a>
  </div>
  
</div>