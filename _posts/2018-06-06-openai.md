---
layout: post
title:  "Solving OpenAI gym's environments using reinforcement and imitation learning techniques"
date:   2018-04-03
categories: [rl]
description: My solutions to tackle a few of OpenAI gym's environments using RL and imitation learning.
tags: reinforcement learning, dqn, policy gradient, gail, ppo, openai gym, cartpole, bipedwalker, gazebo, breakout, tensorflow, pytorch, 

---

<p>
<div class="image-wrapper">
                <a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/openaigym.jpg" title="openai">
                    <img src="https://nav74neet.github.io/media/blog/openaigym/openaigym.jpg" alt="openai" align="middle">
                </a>
</div>
</p>
<br>

## What's this post about?
<p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
This post mainly focuses on the implementation of RL and imitation learning techniques for classical OpenAI gym' environments like cartpole-v0, breakout, mountain car, bipedwalker-v2, etc. I have implemented several RL algorithms such as dqn, policy gradient, etc. as well as generative adversaral learning approach like GAIL for imitation learning. I would like to sincerely thank my colleague Arun Kumar for his constant help and valuable expertise in this work.       
</p>

## Reinforcment learning techniques.
<div class="row">
 <div class="col-md-9">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[1] Deep Q-Networks for Breakout-v0</b>: Maximize the score in the Atari 2600 game Breakout. In this environment, the observation is an RGB image of the screen, which is an array of shape (210, 160, 3) Each action is repeatedly performed for a duration of kkk frames, where kkk is uniformly sampled from {2,3,4}. 
          </p>
          <p>
          <a href="https://github.com/nav74neet/rl_gym/tree/master/breakout" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-3">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/breakout-v0.gif" title="breakout">
    <img src="https://nav74neet.github.io/media/blog/openaigym/breakout-v0.gif" alt="breakout">
    </a>
  </div>
  
</div>

---

<div class="row">
 <div class="col-md-9">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[2] DQN & Policy Gradient for CartPole-v1</b>: Cartpole - known also as an Inverted Pendulum is a pendulum with a center of gravity above its pivot point. Itâ€™s unstable, but can be controlled by moving the pivot point under the center of mass. The goal is to keep the cartpole balanced by applying appropriate forces to a pivot point. A reward of +1 is provided for every timestep that the pole remains upright. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center. 
          </p>
          <p>
          <a href="https://github.com/nav74neet/rl_gym/tree/master/cartpole" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-3">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/cartpole.gif" title="cart">
    <img src="https://nav74neet.github.io/media/blog/openaigym/cartpole.gif" alt="cart">
    </a>
  </div>
  
</div>

---

<div class="row">
 <div class="col-md-9">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[3] Policy Gradient for custom CartPole model in Gazebo</b>: Policy gradient method based on actor-critic learning framework is implemented over the custom cartpole environment in gazebo simulation environment. 
          </p>
          <p>
          <a href="https://github.com/nav74neet/rl_gym/tree/master/cartpole_gazebo" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-3">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/pg2.gif" title="gazebo">
    <img src="https://nav74neet.github.io/media/blog/openaigym/pg2.gif" alt="gazebo">
    </a>
  </div>
  
</div>

---

<div class="row">
 <div class="col-md-9">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[3] DQN & Policy Gradient for MountainCar-v0</b>: A car is on a one-dimensional track, positioned between two "mountains". The goal is to drive up the mountain on the right; however, the car's engine is not strong enough to scale the mountain in a single pass. Therefore, the only way to succeed is to drive back and forth to build up momentum.
          </p>
          <p>
          <a href="https://github.com/nav74neet/rl_gym/tree/master/mountaincar" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-3">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/mountain-car-v0.gif" title="car">
    <img src="https://nav74neet.github.io/media/blog/openaigym/mountain-car-v0.gif" alt="car">
    </a>
  </div>
  
</div>

---

## Imitation learning techniques.
<div class="row">
 <div class="col-md-9">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[1] GAIL for cartpole-v0 </b>: A TensorFlow implementation of Generatve Adversarial Imitation Learning (GAIL) and Behavioural Cloning (BC) for classic cartpole-v0 environment from OpenAI Gym. The expert policies are generated using Proximal Policy Optimization (PPO). 
          <ul>
	 		<li><b>State space:</b>Continuos</li>
  			<li><b>Action Space:</b>Discrete</li>
  		  </ul> 
        </p>
        <p>
          <a href="https://github.com/nav74neet/gail_gym/tree/master/gail-ppo-tf-gym" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-3">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/test_gail.gif" title="gail">
    <img src="https://nav74neet.github.io/media/blog/openaigym/test_gail.gif" alt="gail">
    </a>
  </div>
  
</div>

---

<div class="row">
 <div class="col-md-8">
        <p style="text-align:justify; font-family: 'Merriweather', 'Hiragino Sans GB', 'Microsoft YaHei', 'WenQuanYi Micro Hei', sans-serif;">
          <b>[2] GAIL for bipedwalker-v2</b>: Pytorch implementation of Generatve Adversarial Imitation Learning (GAIL) for bipedwalker-v2 environment from OpenAI Gym. The expert policies are generated using Proximal Policy Optimization (PPO). 
          <ul>
	 		<li><b>State space:(Continuos) </b>(1) hull angle, (2) angular velocity, (3) horizontal speed, (4) vertical speed, (5) position of joints (6) joints angular speed, (7) legs contact with ground, and (8) lidar rangefinder measurements</li>
  			<li><b>Action Space:(Continuos) </b>joint motor torques</li>
  		  </ul> 
        </p>
        <p>
          <a href="https://github.com/nav74neet/gail_gym/tree/master/gail-ppo-pytorch-gym" class="md-link btn-default btn rbtn">Code</a>
        </p>
 </div>

  <div class="col-md-4">
  	<a class ="image-popup" href="https://nav74neet.github.io/media/blog/openaigym/gail.gif" title="gail2">
    <img src="https://nav74neet.github.io/media/blog/openaigym/gail.gif" alt="gail2">
    </a>
  </div>
  
</div>

---